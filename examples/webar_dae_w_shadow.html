<!DOCTYPE html>
<html lang="en">
<head>
  <title>three.ar.js - Load Model</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, user-scalable=no,
  minimum-scale=1.0, maximum-scale=1.0">
  <style>
    body {
      font-family: monospace;
      margin: 0;
      overflow: hidden;
      position: fixed;
      width: 100%;
      height: 100vh;
      -webkit-user-select: none;
      user-select: none;
    }
    canvas {
      position: absolute;
      top: 0;
      left: 0;
    }
    #info {
      position: absolute;
      left: calc(50% - 75px);
      bottom: 10px;
      z-index: 10;
      display: block;
      text-align: center;
      background-color: rgba(0, 0,  0, 0.4);
      padding: 4px 8px;
    }
    #info a {
      color: white;
      text-decoration: none;
    }
  </style>
</head>
<body>
<div id="info">
  <a href="index.html">webar experiments</a>
</div>

<canvas id="canvas_fuzzy_wobble"></canvas>

<script src="../../lib/threejs_ar/third_party/three.js/three.js"></script>
<script src="../../lib/threejs_ar/dist/three.ar.js"></script>
<script src="../../lib/threejs_ar/third_party/three.js/VRControls.js"></script>
<script src="../../lib/threejs_addons/ColladaLoader.js"></script>
<script src="../../lib/threejs_addons/inflate.min.js"></script>

<script src="../../lib/hammer.js"></script>

<script>

var model_init_scale = 1.0;

var model_rotation = 0;
var model_scale = 1.0;


      var myElement = document.getElementById('canvas_fuzzy_wobble');
      var manager = new Hammer.Manager(myElement);
      var pinch = new Hammer.Pinch();
      var swipe = new Hammer.Swipe();
      var pan = new Hammer.Pan();
      manager.add([pinch, swipe, pan]);
      // manager.on('pinch', function(e) {
      //     alert(e);
      // });
      manager.on('panstart', function(e) {
          console.log(e);
      });
      manager.on('panend', function(e) {
          console.log(e);
      });   
      manager.on('pan', function(e) {

        if(Math.abs(e.deltaX)>20){
            var rot = e.deltaX / 1000;
            model_rotation += rot;
            console.log("delatX: "+rot);
            console.log("Rotation: "+model_rotation);

            model.rotation.set(0, model_rotation, 0);

        }

        if(Math.abs(e.deltaY)>20){
            var scl = (e.deltaY/5000) * model_init_scale;
            model_scale -= scl;
            if(model_scale<0.10){model_scale = 0.10;}
            if(model_scale>10){model_scale = 10;}
            console.log("delatY: "+scl);
            console.log("Scale: "+model_scale);

            var s = model_scale*model_init_scale;
            model.scale.set( s,s,s );

        }

      }); 



//https://mrdoob.github.io/webar-experiments/

var vrDisplay;
var vrControls;
var arView;

var canvas;
var camera;
var scene;
var renderer;
var model;

var shadowMesh;
var planeGeometry;
var light;
var directionalLight;

var clock = new THREE.Clock();

var mixers = [];

/**
 * Use the `getARDisplay()` utility to leverage the WebVR API
 * to see if there are any AR-capable WebVR VRDisplays. Returns
 * a valid display if found. Otherwise, display the unsupported
 * browser message.
 */
THREE.ARUtils.getARDisplay().then(function (display) {
  if (display) {
    vrDisplay = display;
    init();
  } else {
    THREE.ARUtils.displayUnsupportedMessage();
  }
});

function init() {

  scene = new THREE.Scene();

  // Turn on the debugging panel
  var arDebug = new THREE.ARDebug(vrDisplay, scene, {
    showLastHit: false,
    showPoseStatus: false,
    showPlanes: true
  } );
  document.body.appendChild(arDebug.getElement());

  // Setup the three.js rendering environment
  var container = document.getElementById( 'canvas_fuzzy_wobble' );
  renderer = new THREE.WebGLRenderer({ canvas: container, alpha: true });
  renderer.setPixelRatio(window.devicePixelRatio);
  renderer.setSize(window.innerWidth, window.innerHeight);
  renderer.autoClear = false;
  canvas = renderer.domElement;
  // document.body.appendChild(canvas);

  // Creating the ARView, which is the object that handles
  // the rendering of the camera stream behind the three.js
  // scene
  arView = new THREE.ARView(vrDisplay, renderer);

  // The ARPerspectiveCamera is very similar to THREE.PerspectiveCamera,
  // except when using an AR-capable browser, the camera uses
  // the projection matrix provided from the device, so that the
  // perspective camera's depth planes and field of view matches
  // the physical camera on the device.
  camera = new THREE.ARPerspectiveCamera(
    vrDisplay,
    60,
    window.innerWidth / window.innerHeight,
    vrDisplay.depthNear,
    vrDisplay.depthFar
  );

  // VRControls is a utility from three.js that applies the device's
  // orientation/position to the perspective camera, keeping our
  // real world and virtual world in sync.
  vrControls = new THREE.VRControls(camera);

  // For shadows to work
  renderer.shadowMap.enabled = true;
  renderer.shadowMap.type = THREE.PCFSoftShadowMap;

  // The materials in Poly models will render as a black mesh
  // without lights in our scenes. Let's add an ambient light
  // so our model can be scene, as well as a directional light
  // for the shadow
  directionalLight = new THREE.DirectionalLight();
  // @TODO in the future, use AR light estimation
  directionalLight.intensity = 0.5;
  directionalLight.position.set(-1, 15, 1);
  // We want this light to cast shadow
  directionalLight.castShadow = true;
  directionalLight.shadow.camera.zoom = 5.0;
  light = new THREE.AmbientLight();
  scene.add(light);
  scene.add(directionalLight);

  // Make a large plane to receive our shadows
  planeGeometry = new THREE.PlaneGeometry(2000, 2000);
  // Rotate our plane to be parallel to the floor
  planeGeometry.rotateX(-Math.PI / 2);

  // Create a mesh with a shadow material, resulting in a mesh
  // that only renders shadows once we flip the `receiveShadow` property
  shadowMesh = new THREE.Mesh(planeGeometry, new THREE.ShadowMaterial({
    color: 0x111111,
    opacity: 0.15,
  }));
  shadowMesh.receiveShadow = true;
  scene.add(shadowMesh);

  var loader = new THREE.ColladaLoader();
  loader.load( '../../lib/models/dae/boomer/boomer_d1.dae', function (collada) {

    model = collada.scene;

    model.traverse( function (mesh) {

      if ( mesh.isMesh ) {

        mesh.castShadow = true;
        mesh.receiveShadow = true;

        // workarounds

        mesh.frustumCulled = false;

      }

    } );
    model.position.set(10000, 10000, 10000);
    model.scale.setScalar( model_init_scale );
    scene.add(model);

    //

    var animations = collada.animations;

    var mixer = new THREE.AnimationMixer(model);
    mixer.clipAction(animations[0]).play();
    mixers.push(mixer);

  } );

  // Bind our event handlers
  window.addEventListener('resize', onWindowResize, false);
  canvas.addEventListener('click', onClick, false);

  // Kick off the render loop!
  update();
}

/**
 * The render loop, called once per frame. Handles updating
 * our scene and rendering.
 */
function update() {
  // Clears color from the frame before rendering the camera (arView) or scene.
  renderer.clearColor();

  // Render the device's camera stream on screen first of all.
  // It allows to get the right pose synchronized with the right frame.
  arView.render();

  // Update our camera projection matrix in the event that
  // the near or far planes have updated
  camera.updateProjectionMatrix();

  // Update our perspective camera's positioning
  vrControls.update();

  if ( mixers.length > 0 ) {

    for ( var i = 0; i < mixers.length; i ++ ) {

      mixers[ i ].update( clock.getDelta() );

    }

  }

  // Render our three.js virtual scene
  renderer.clearDepth();
  renderer.render(scene, camera);

  // Kick off the requestAnimationFrame to call this function
  // when a new VRDisplay frame is rendered
  vrDisplay.requestAnimationFrame(update);
}

/**
 * On window resize, update the perspective camera's aspect ratio,
 * and call `updateProjectionMatrix` so that we can get the latest
 * projection matrix provided from the device
 */
function onWindowResize () {
  camera.aspect = window.innerWidth / window.innerHeight;
  camera.updateProjectionMatrix();
  renderer.setSize(window.innerWidth, window.innerHeight);
}

/**
 * When clicking on the screen, fire a ray from where the user clicked
 * on the screen and if a hit is found, place a cube there.
 */
function onClick (e) {
  // Inspect the event object and generate normalize screen coordinates
  // (between 0 and 1) for the screen position.
  var x = e.clientX / window.innerWidth;
  var y = e.clientY / window.innerHeight;

  // Send a ray from the point of click to the real world surface
  // and attempt to find a hit. `hitTest` returns an array of potential
  // hits.
  var hits = vrDisplay.hitTest(x, y);

  if (!model) {
    console.warn('Model not yet loaded');
    return;
  }

  // If a hit is found, just use the first one
  if (hits && hits.length) {
    var hit = hits[0];

    // Turn the model matrix from the VRHit into a
    // THREE.Matrix4 so we can extract the position
    // elements out so we can position the shadow mesh
    // to be directly under our model. This is a complicated
    // way to go about it to illustrate the process, and could
    // be done by manually extracting the "Y" value from the
    // hit matrix via `hit.modelMatrix[13]`
    var matrix = new THREE.Matrix4();
    var position = new THREE.Vector3();
    matrix.fromArray(hit.modelMatrix);
    position.setFromMatrixPosition(matrix);

    // Set our shadow mesh to be at the same Y value
    // as our hit where we're placing our model
    // @TODO use the rotation from hit.modelMatrix
    shadowMesh.position.y = position.y;

    // Use the `placeObjectAtHit` utility to position
    // the cube where the hit occurred
    THREE.ARUtils.placeObjectAtHit(model,  // The object to place
                                   hit,   // The VRHit object to move the cube to
                                   1,     // Easing value from 0 to 1; we want to move
                                          // the cube directly to the hit position
                                   true); // Whether or not we also apply orientation

    // Rotate the model to be facing the user
    // var angle = Math.atan2(
    //   camera.position.x - model.position.x,
    //   camera.position.z - model.position.z
    // );
    // model.rotation.set(0, angle, 0);
  }
}
</script>
</body>
</html>
